---
title: "Model"
format: pdf
editor: visual
---

```{r}
library(tidyverse)
library(car)
```

```{r}
data_train <- read.csv("data-train.csv")
data_test <- read.csv("data-test.csv")
```

##Data Cleaning

```{r}
# Change Fr and Re to categorical
data_train$Fr <- as.factor(data_train$Fr)
data_train$Re <- as.factor(data_train$Re)
```


# Plots for Linear Model 1 (First Moment)

```{r}
par(mfrow = c(2,2))
plot(lm_moment1)
```

# Adjusted Linear Model 1

```{r}
adjusted_lm_moment1 <- lm(log(R_moment_1) ~ poly(St, 2) * Re * Fr, data = data_train) #Make St quadratic
summary(adjusted_lm_moment1)
par(mfrow = c(2,2))
plot(adjusted_lm_moment1)

#note: log response
#The Q–Q plot for the adjusted model (with quadratic St and interactions) indicates that while the central residuals are approximately normal, several extreme points deviate substantially from the expected line. This suggests the presence of heavy tails and influential cases, likely arising from extreme parameter settings. A log transformation of the response or a robust regression approach can mitigate these effects and improve model normality.

#note: ploy term
#Initial diagnostic plots revealed a systematic pattern in the residuals, suggesting that the effect of the Stokes number (St) on the mean cluster volume was nonlinear. To capture this curvature, we included a second-order polynomial term, poly(St, 2), which adds both linear and quadratic components of St to the model. This adjustment improves model flexibility while maintaining interpretability.

##TODO: Find which interaction effects are significant
```

# FINAL: moment 1 model
```{r}
#make a GLM
glm_moment1 <-glm(R_moment_1 ~ St*Fr + Re, data = data_train, family = Gamma(link = "log"))
summary(glm_moment1)
par(mfrow = c(2,2))
plot(glm_moment1)
```

#Moment 1 CV

```{r}
library(boot)

cv_results <- cv.glm(data_train, glm_moment1, K = 10)
cv_results$delta
```

Very small CV error. The model generalizes well within the sample (i.e., not just memorizing).

#Calculate Variance (Central Statistic 2)

```{r}
data_train$Var_empirical <- data_train$R_moment_2 - data_train$R_moment_1^2
```


#ANOVA to determine order of polynomial #??Should I include the interaction effect even though it's less interpretable? Should I do CV to determine?

```{r}
adjusted_lm_moment2 <- lm(log(Var_empirical)~ poly(St,2)+ Re*Fr, data = data_train)
lm_linear <- lm(log(Var_empirical) ~ St + Re*Fr, data = data_train)
anova(lm_linear, adjusted_lm_moment2)
```

#Adjusted LM2 #should I add a spline to improve the Q-Q plot? (only 4 outliers)

```{r}
summary(adjusted_lm_moment2)
par(mfrow = c(2,2))
plot(adjusted_lm_moment2)
```

#Moment 2 CV

```{r}
set.seed(123)
K <- 10
folds <- sample(rep(1:K, length.out = nrow(data_train)))

rmse <- numeric(K)
for(k in 1:K){
  train_idx <- folds != k
  test_idx  <- folds == k

  fit <- lm(log(Var_empirical) ~ poly(St, 2) + Re *Fr, data=data_train[train_idx,])
  preds_log <- predict(fit, newdata=data_train[test_idx,])
  obs_log <- log(data_train$R_moment_2[test_idx])
  rmse[k] <- sqrt(mean((obs_log - preds_log)^2))
}
mean(rmse)
```

Very close to model's in-sample RSE = 1.73. This means there’s little to no overfitting — out-of-sample performance matches training performance very closely.

#FINAL: Moment 2 model
```{r}
# adds spline
library(mgcv)

# Fit a Gamma GAM with log link
gam_var <- gam(
  Var_empirical ~ s(St, k = 4) + Re * Fr,
  data = data_train,
  family = Gamma(link = "log")
)

# View model summary
summary(gam_var)
par(mfrow = c(2, 2))
gam.check(gam_var)
plot(gam_var, pages = 1, shade = TRUE)
```

#CV w/ Spline

```{r}
set.seed(123)
K <- 10
folds <- sample(rep(1:K, length.out = nrow(data_train)))
rmse <- numeric(K)

for (k in 1:K) {
  train_idx <- folds != k
  test_idx  <- folds == k
  
  fit <- gam(
    Var_empirical ~ s(St, k = 4) + Re * Fr,
    data = data_train[train_idx, ],
    family = Gamma(link = "log")
  )
  
  preds_log <- predict(fit, newdata = data_train[test_idx, ], type = "link")
  obs_log <- log(data_train$Var_empirical[test_idx])
  
  rmse[k] <- sqrt(mean((obs_log - preds_log)^2))
}

mean(rmse)
```

#Moment 3

```{r}
plot(lm_moment3)
```

```{r}
data_train <- data_train %>%
  mutate(
    Central_m2 = R_moment_2 - R_moment_1^2,
    Central_m3 = R_moment_3 - 3 * R_moment_2 * R_moment_1 + 2 * R_moment_1^3,
    Skew_Standardized = Central_m3 / (Central_m2^(3/2)),
  ) %>%
  filter(!is.na(Skew_Standardized), is.finite(Skew_Standardized))

lm_poly1 <- lm(Skew_Standardized ~ St + Re * Fr, data = data_train)
lm_poly2 <- lm(Skew_Standardized ~ poly(St, 2) + Re * Fr, data = data_train)
lm_poly3 <- lm(Skew_Standardized ~ poly(St, 3) + Re * Fr, data = data_train)
lm_poly4 <- lm(Skew_Standardized ~ poly(St, 4) + Re * Fr, data = data_train)


anova(lm_poly1, lm_poly2, lm_poly3, lm_poly4)


```
#FINAL: moment 3 model
```{r}
# MODEL 3: skewness

library(dplyr)
library(caret)
library(splines)
library(ggplot2)
set.seed(123)


# ---- 5-Fold CV ----
folds <- createFolds(data_train$Skew_Standardized, k = 5)

cv_error <- function(fit_func) {
  mean(sapply(folds, function(idx) {
    train <- data_train[-idx, ]
    test  <- data_train[idx, ]
    model <- fit_func(train)
    preds <- predict(model, newdata = test)
    mean((test$Skew_Standardized - preds)^2, na.rm = TRUE)
  }))
}

# 


#1. why did we standardize skew ? 
#2. why poly of that order? 
  # run ANOVA
#3. why a spline of df 4
  # anova equivalent for splines

lm_raw    <- function(d) lm(Skew_Standardized ~ poly(St, 2) + Re * Fr, data = d)
lm_spline <- function(d) lm(Skew_Standardized ~ bs(St, df = 4) + Re * Fr, data = d)

# Run Cv
results <- tibble(
  Model = c("lm_raw", "lm_spline"),
  MSE = c(cv_error(lm_raw), cv_error(lm_spline))
)

print(results)

# Best model
best_name <- results$Model[which.min(results$MSE)]
cat("Best model:", best_name, "\n")

best_model <- switch(best_name,
  lm_raw = lm_raw(data_train),
  lm_spline = lm_spline(data_train)
)

summary(best_model)

# Plots
par(mfrow = c(2, 2))
plot(best_model)   # Residuals, Q-Q, leverage, etc.


```

#Andy
```{r}
plot(lm_moment4)
```

```{r}
adjusted_lm_moment4 <- lm(R_moment_4 ~ poly(St, 2) * Re * Fr, data = data_train) #Make St quadratic
summary(adjusted_lm_moment4)
plot(adjusted_lm_moment4)
```

```{r}
# add columns to training data
data_train <- data_train %>%
  mutate(
    Central_m4 = R_moment_4 - 4 * R_moment_3 * R_moment_1 +
                 6 * R_moment_2 * R_moment_1^2 - 3 * R_moment_1^4,
    Kurt_Standardized = Central_m4 / (Central_m2^2),
  ) %>%
  filter(!is.na(Kurt_Standardized), is.finite(Kurt_Standardized))
```

```{r}
# CV on a bunch of different models
set.seed(123)
cv_folds <- createFolds(data_train$Kurt_Standardized, k = 5)

cv_error_log <- function(fit_func) {
  mean(sapply(cv_folds, function(idx) {
    train <- data_train[-idx, ]
    test  <- data_train[idx, ]
    model <- fit_func(train)
    preds_log <- predict(model, newdata = test)
    preds_raw <- exp(preds_log)
    mean((test$Kurt_Standardized - preds_raw)^2, na.rm = TRUE)
  }))
}

cv_error_raw <- function(fit_func) {
  mean(sapply(cv_folds, function(idx) {
    train <- data_train[-idx, ]
    test  <- data_train[idx, ]
    model <- fit_func(train)
    preds <- predict(model, newdata = test)
    mean((test$Kurt_Standardized - preds)^2, na.rm = TRUE)
  }))
}

linear <- function(d) lm(Kurt_Standardized ~ St + Re + Fr, data = d)
simple <- function(d) lm(Kurt_Standardized ~ poly(St, 2) + Re * Fr, data = d)
interact <- function(d) lm(Kurt_Standardized ~ poly(St, 2) * Re + Re * Fr, data = d)
transform <- function(d) lm(log(Kurt_Standardized) ~ poly(St, 2) * Re + Re * Fr, data = d)
spline <- function(d) lm(Kurt_Standardized ~ ns(St, df = 4) + Re * Fr, data = d)

cv_error_raw(linear)
cv_error_raw(simple)
cv_error_raw(interact)
cv_error_log(transform)
cv_error_raw(spline)



```

#FINAL: moment 4 model
```{r}
# "simple" model from above performed best during CV
model4 <- lm(Kurt_Standardized ~ poly(St, 2) + Re * Fr, data = data_train)

summary(model4)
plot(model4)

# Residuals vs Fitted & Scale-Location plot look a bit sus, tried adding spline but it didnt help
```
