---
title: "Model"
format: pdf
editor: visual
---

```{r}
library(tidyverse)
library(car)
```

```{r}
data_train <- read.csv("data-train.csv")
data_test <- read.csv("data-test.csv")
```

##Data Cleaning

```{r}
# Change Fr and Re to categorical
data_train$Fr <- as.factor(data_train$Fr)
data_train$Re <- as.factor(data_train$Re)

```

## Initial linear models

```{r}
lm_moment1 <- lm(R_moment_1 ~ St + Re + Fr, data = data_train)
lm_moment2 <- lm(R_moment_2 ~ St + Re + Fr, data = data_train)
lm_moment3 <- lm(R_moment_3 ~ St + Re + Fr, data = data_train)
lm_moment4 <- lm(R_moment_4 ~ St + Re + Fr, data = data_train)

summary(lm_moment1)
summary(lm_moment2)
summary(lm_moment3)
summary(lm_moment4)

```
# Plots for Linear Model 1 (First Moment)
```{r}
par(mfrow = c(2,2))
plot(lm_moment1)
```
# Adjusted Linear Model 1 
```{r}
adjusted_lm_moment1 <- lm(log(R_moment_1) ~ poly(St, 2) * Re * Fr, data = data_train) #Make St quadratic
summary(adjusted_lm_moment1)
par(mfrow = c(2,2))
plot(adjusted_lm_moment1)

#note: log response
#The Q–Q plot for the adjusted model (with quadratic St and interactions) indicates that while the central residuals are approximately normal, several extreme points deviate substantially from the expected line. This suggests the presence of heavy tails and influential cases, likely arising from extreme parameter settings. A log transformation of the response or a robust regression approach can mitigate these effects and improve model normality.

#note: ploy term
#Initial diagnostic plots revealed a systematic pattern in the residuals, suggesting that the effect of the Stokes number (St) on the mean cluster volume was nonlinear. To capture this curvature, we included a second-order polynomial term, poly(St, 2), which adds both linear and quadratic components of St to the model. This adjustment improves model flexibility while maintaining interpretability.

##TODO: Find which interaction effects are significant
```

#remove insignificant interaction effects

```{r}
adjusted_lm_moment1 <- lm(log(R_moment_1) ~ poly(St, 2) * Fr + Re:Fr, data = data_train) #Make St quadratic
summary(adjusted_lm_moment1)
par(mfrow = c(2,2))
plot(adjusted_lm_moment1)
```

# GLM
```{r}
glm_moment1 <-glm(R_moment_1 ~ St*Fr + Re, data = data_train, family = Gamma(link = "log"))
summary(glm_moment1)
par(mfrow = c(2,2))
plot(glm_moment1)
```
#Moment 1 CV
```{r}
library(boot)

cv_results <- cv.glm(data_train, glm_moment1, K = 10)
cv_results$delta
```
Very small CV error. The model generalizes well within the sample (i.e., not just memorizing).

# Simple LM 2 Plot
```{r}
par(mfrow = c(2,2))
plot(lm_moment2)
```
#ANOVA to determine order of polynomial
```{r}
adjusted_lm_moment2 <- lm(log(R_moment_2)~ poly(St,2)+ Re + Fr, data = data_train)
lm_linear <- lm(log(R_moment_2) ~ St + Re + Fr, data = data_train)
anova(lm_linear, adjusted_lm_moment2)
```

#Adjusted LM2
```{r}
#glm_moment2 <-glm(R_moment_2 ~ poly(St,1) + Re + Fr, data = data_train, family = Gamma(link = "log"))
summary(adjusted_lm_moment2)
par(mfrow = c(2,2))
plot(adjusted_lm_moment2)
```

#Moment 2 CV
```{r}
set.seed(123)
K <- 10
folds <- sample(rep(1:K, length.out = nrow(data_train)))

rmse <- numeric(K)
for(k in 1:K){
  train_idx <- folds != k
  test_idx  <- folds == k

  fit <- lm(log(R_moment_2) ~ poly(St, 2) + Re + Fr, data=data_train[train_idx,])
  preds_log <- predict(fit, newdata=data_train[test_idx,])
  obs_log <- log(data_train$R_moment_2[test_idx])
  rmse[k] <- sqrt(mean((obs_log - preds_log)^2))
}
mean(rmse)
```
Very close to model's in-sample RSE = 1.73. This means there’s little to no overfitting — out-of-sample performance matches training performance very closely.




#Ty
```{r}
plot(lm_moment3)
```

```{r}
adjusted_lm_moment3 <- lm(R_moment_3 ~ poly(St, 2) * Re * Fr, data = data_train) #Make St quadratic
summary(adjusted_lm_moment3)
plot(adjusted_lm_moment3)
```

#Andy
```{r}
plot(lm_moment4)
```

```{r}
adjusted_lm_moment4 <- lm(R_moment_4 ~ poly(St, 2) * Re * Fr, data = data_train) #Make St quadratic
summary(adjusted_lm_moment4)
plot(adjusted_lm_moment4)
```
